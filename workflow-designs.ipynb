{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e192875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/mambaforge/envs/llm-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "def _set_env(var: str):\n",
    "    load_dotenv() # load from .env file\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60981e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_query='Calcium CT score and high cholesterol relationship' justification='The user is asking about the relationship between Calcium CT score and high cholesterol. This search query directly addresses that relationship.'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = Field(None, description=\"Query that is optimized web search.\")\n",
    "    justification: str = Field(\n",
    "        None, description=\"Why this query is relevant to the user's request.\"\n",
    "    )\n",
    "\n",
    "# augment llm with schema for structured output    \n",
    "structured_llm = llm.with_structured_output(SearchQuery)\n",
    "\n",
    "# Invoke the augmented LLM\n",
    "output = structured_llm.invoke(\"How does Calcium CT score relate to high cholesterol?\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc51832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2.0, 'b': 3.0},\n",
       "  'id': '6c6a9d5c-43d7-4ffd-9f7d-aa02c7716a67',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define a tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    return a * b\n",
    "\n",
    "# Augment the LLM with tools\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "# Invoke the LLM with input that triggers the tool call\n",
    "msg = llm_with_tools.invoke(\"What is 2 times 3?\")\n",
    "\n",
    "# Get the tool call\n",
    "msg.tool_calls\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce4c7b",
   "metadata": {},
   "source": [
    "## Prompt chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66902f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial joke:\n",
      "Why did the dog sit in the shade?\n",
      "\n",
      "Because he didn't want to be a hot dog!\n",
      "\n",
      "--- --- ---\n",
      "\n",
      "Joke failed quality gate - no punchline detected!\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    improved_joke: str\n",
    "    final_joke: str\n",
    "    \n",
    "# nodes\n",
    "def generate_joke(state: State):\n",
    "    \"\"\" gen initial joke \"\"\"\n",
    "    msg = llm.invoke(f\"write a short joke about {state[\"topic\"]}\")\n",
    "    return {\"joke\" : msg.content}\n",
    "\n",
    "def check_punchline(state: State):\n",
    "    \"\"\"Gate function to check if the joke has a punchline\"\"\"\n",
    "\n",
    "    # Simple check - does the joke contain \"?\" or \"!\"\n",
    "    if \"?\" in state[\"joke\"] or \"!\" in state[\"joke\"]:\n",
    "        return \"Pass\"\n",
    "    return \"Fail\"\n",
    "\n",
    "\n",
    "def improve_joke(state: State):\n",
    "    \"\"\"Second LLM call to improve the joke\"\"\"\n",
    "\n",
    "    msg = llm.invoke(f\"Make this joke funnier by adding wordplay: {state['joke']}\")\n",
    "    return {\"improved_joke\": msg.content}\n",
    "\n",
    "\n",
    "def polish_joke(state: State):\n",
    "    \"\"\"Third LLM call for final polish\"\"\"\n",
    "\n",
    "    msg = llm.invoke(f\"Add a surprising twist to this joke: {state['improved_joke']}\")\n",
    "    return {\"final_joke\": msg.content}\n",
    "\n",
    "\n",
    "# build workflow\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"generate_joke\", generate_joke)\n",
    "workflow.add_node(\"improve_joke\", improve_joke)\n",
    "workflow.add_node(\"polish_joke\", polish_joke)\n",
    "\n",
    "# add edges to connect nodes\n",
    "workflow.add_edge(START, \"generate_joke\")\n",
    "workflow.add_conditional_edges(\"generate_joke\", check_punchline, {\"Fail\" : \"improve_joke\", \"Pass\" : END})\n",
    "workflow.add_edge(\"improve_joke\", \"polish_joke\")\n",
    "workflow.add_edge(\"polish_joke\", END)\n",
    "\n",
    "chain = workflow.compile()\n",
    "\n",
    "# show workflow in UI\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "state = chain.invoke({\"topic\": \"dogs\"})\n",
    "print(\"Initial joke:\")\n",
    "print(state[\"joke\"])\n",
    "print(\"\\n--- --- ---\\n\")\n",
    "if \"improved_joke\" in state:\n",
    "    print(\"Improved joke:\")\n",
    "    print(state[\"improved_joke\"])\n",
    "    print(\"\\n--- --- ---\\n\")\n",
    "\n",
    "    print(\"Final joke:\")\n",
    "    print(state[\"final_joke\"])\n",
    "else:\n",
    "    print(\"Joke failed quality gate - no punchline detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d203acc",
   "metadata": {},
   "source": [
    "## Orchestrator-worker architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774820e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sections=[Section(name='Introduction to LLM Scaling Laws', description='Overview of what LLM scaling laws are, their importance in the field of AI, and a brief history of their development.'), Section(name='Key Scaling Laws and Models', description='Detailed explanation of the fundamental scaling laws (e.g., Chinchilla scaling laws) and how they apply to different model architectures and sizes.'), Section(name='Empirical Evidence and Case Studies', description='Presentation of empirical studies and real-world examples demonstrating the effectiveness of scaling laws in improving LLM performance.'), Section(name='Implications and Future Directions', description='Discussion on the implications of scaling laws for future AI research, potential limitations, and emerging trends in the field.')]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Introduction to LLM Scaling Laws\n",
       "\n",
       "Large Language Model (LLM) scaling laws describe the empirical relationships observed between the performance of language models and key factors such as model size (number of parameters), dataset size, and computational budget. These laws have emerged as a fundamental concept in the field of Artificial Intelligence, providing a predictive framework for understanding how LLMs improve with increased resources. Their importance lies in guiding the development and deployment of increasingly capable AI systems, allowing researchers and engineers to anticipate performance gains and optimize resource allocation.\n",
       "\n",
       "The development of LLM scaling laws can be traced back to early observations in machine learning regarding the benefits of larger models and datasets. However, the systematic study and formalization of these relationships for modern neural language models gained significant traction with the advent of transformer architectures and the availability of massive datasets. Landmark research, particularly from organizations like OpenAI and DeepMind, has demonstrated consistent power-law relationships between performance metrics (e.g., loss, accuracy on downstream tasks) and the scale of these key factors. These findings have revolutionized how we approach the training of LLMs, shifting the focus from architectural innovation alone to a more resource-centric perspective. Understanding these laws is crucial for navigating the exponential growth in LLM capabilities and for making informed decisions about future research and development.\n",
       "\n",
       "---\n",
       "\n",
       "## Key Scaling Laws and Models\n",
       "\n",
       "The performance of large language models (LLMs) is demonstrably linked to the scale of their training data and the number of parameters in the model. Understanding these relationships, often referred to as \"scaling laws,\" is crucial for efficient model development and deployment.\n",
       "\n",
       "### Chinchilla Scaling Laws\n",
       "\n",
       "The Chinchilla scaling laws, proposed by Hoffmann et al. (2022), represent a significant advancement in understanding optimal resource allocation for LLM training. Prior to Chinchilla, a common heuristic was to train larger models on less data. Chinchilla demonstrated that for a given compute budget, it is more effective to train a smaller model on more data. Specifically, the study found that for optimal performance, the number of training tokens should scale proportionally with the number of model parameters.\n",
       "\n",
       "The core finding of the Chinchilla paper suggests that for a fixed compute budget, the optimal model size and dataset size are roughly equal. This implies that many previously trained large models were undertrained, meaning they could have achieved better performance with the same compute budget by using a smaller model and more data.\n",
       "\n",
       "The empirical relationship observed can be approximated by:\n",
       "\n",
       "*   **Model Size (Parameters):** $N \\propto C^{0.5}$\n",
       "*   **Training Tokens:** $D \\propto C^{0.5}$\n",
       "\n",
       "Where $C$ is the total compute budget. This suggests a balanced approach to scaling both parameters and data.\n",
       "\n",
       "### Application to Different Model Architectures and Sizes\n",
       "\n",
       "The Chinchilla scaling laws, while derived from transformer-based models, provide a general framework that can inform the scaling strategies for various LLM architectures and sizes.\n",
       "\n",
       "*   **Transformer Architectures:** The transformer architecture, with its self-attention mechanism, has proven highly effective for capturing long-range dependencies in text. The scaling laws are particularly relevant here, as the computational cost of self-attention grows quadratically with sequence length, and the number of parameters influences the model's capacity to learn complex patterns. Chinchilla's findings suggest that for a given compute budget, increasing the number of training tokens for a transformer model is often more beneficial than simply increasing the number of layers or attention heads beyond a certain point.\n",
       "\n",
       "*   **Model Size:**\n",
       "    *   **Smaller Models (e.g., < 10B parameters):** For smaller models, the Chinchilla laws suggest that a substantial amount of training data is still crucial. While they may not require the same absolute number of tokens as larger models, the *ratio* of tokens to parameters remains important. Under-training smaller models can lead to suboptimal performance and a failure to fully leverage their capacity.\n",
       "    *   **Medium Models (e.g., 10B - 100B parameters):** This range is where the Chinchilla findings are most directly applicable. Training these models with a balanced approach to parameters and tokens, as suggested by the laws, is likely to yield the best performance for a given compute budget.\n",
       "    *   **Larger Models (e.g., > 100B parameters):** For extremely large models, the sheer number of parameters necessitates a correspondingly massive dataset to avoid under-training. The Chinchilla laws imply that to effectively train a model with hundreds of billions or trillions of parameters, one would need an equally vast number of training tokens. This highlights the immense data requirements for state-of-the-art large models.\n",
       "\n",
       "*   **Other Architectures (e.g., Mixture-of-Experts - MoE):** While Chinchilla was primarily focused on dense transformers, its principles can be adapted to architectures like MoE. In MoE models, only a subset of parameters is activated for each input. This can lead to a different compute-data trade-off. However, the fundamental idea of needing sufficient data to train the activated parameters and the overall model capacity still holds. The optimal scaling for MoE might involve considering the number of active parameters and the data processed by those active parameters.\n",
       "\n",
       "**Implications for Training:**\n",
       "\n",
       "The Chinchilla scaling laws have significant implications for how LLMs are trained:\n",
       "\n",
       "1.  **Resource Allocation:** They provide a data-driven approach to allocating compute, parameter count, and training data. Instead of blindly increasing model size, developers can use these laws to find a more efficient balance.\n",
       "2.  **Dataset Curation:** The emphasis on data quantity underscores the importance of high-quality, diverse, and large-scale datasets.\n",
       "3.  **Model Efficiency:** By identifying undertrained models, the Chinchilla laws enable the development of more performant models for a given computational budget, leading to greater efficiency in research and deployment.\n",
       "4.  **Future Research:** These laws serve as a baseline for future research into more nuanced scaling relationships, potentially incorporating factors like data quality, model architecture variations, and specific task performance.\n",
       "\n",
       "In summary, the Chinchilla scaling laws offer a critical framework for understanding and optimizing the training of LLMs, emphasizing a balanced scaling of model parameters and training data to achieve superior performance within a given compute budget.\n",
       "\n",
       "---\n",
       "\n",
       "## Empirical Evidence and Case Studies\n",
       "\n",
       "The effectiveness of scaling laws in enhancing Large Language Model (LLM) performance is well-documented through numerous empirical studies and real-world case studies. These investigations consistently demonstrate a predictable relationship between model size, dataset size, and computational budget, and the resulting performance improvements across a wide range of natural language processing tasks.\n",
       "\n",
       "### Key Empirical Findings:\n",
       "\n",
       "*   **Power-Law Relationships:** Research, notably from OpenAI and DeepMind, has established that LLM performance, measured by metrics like cross-entropy loss, often follows power-law relationships with respect to model parameters, dataset size, and compute. This means that as these factors increase, performance improves predictably, albeit with diminishing returns at extreme scales.\n",
       "*   **Predictive Power of Scaling Laws:** These studies have shown that scaling laws can accurately predict the performance of larger models based on the performance of smaller models trained with less data and compute. This predictive capability is crucial for efficient resource allocation and for setting realistic performance targets.\n",
       "*   **Emergent Abilities:** Beyond predictable performance gains, scaling has also been observed to lead to \"emergent abilities\" – capabilities that are not present in smaller models but appear suddenly and significantly in larger ones. Examples include few-shot learning, complex reasoning, and code generation. These emergent properties are a direct consequence of scaling and highlight the qualitative shifts in LLM capabilities.\n",
       "*   **Generalization Across Tasks:** The benefits of scaling are not limited to a single task. Studies have shown that larger, well-trained models generalize better across a diverse set of NLP benchmarks, including question answering, summarization, translation, and text generation, often achieving state-of-the-art results.\n",
       "\n",
       "### Case Studies Demonstrating Effectiveness:\n",
       "\n",
       "*   **GPT-3 and its Successors (OpenAI):** The development of the GPT series, particularly GPT-3, is a prime example. GPT-3, with its 175 billion parameters, demonstrated remarkable few-shot and zero-shot learning capabilities, significantly outperforming previous models on many tasks without task-specific fine-tuning. Subsequent models like InstructGPT and GPT-4 have further leveraged scaling principles, incorporating instruction tuning and reinforcement learning from human feedback (RLHF) on top of massive scale, leading to substantial improvements in helpfulness, honesty, and harmlessness.\n",
       "*   **LaMDA and PaLM (Google AI):** Google's Language Model for Dialogue Applications (LaMDA) and Pathways Language Model (PaLM) are other significant examples. LaMDA, trained on a massive dialogue dataset, exhibits impressive conversational fluency and coherence. PaLM, a 540-billion parameter model, demonstrated state-of-the-art performance on numerous benchmarks, including reasoning tasks, and showcased the benefits of scaling across a dense transformer architecture.\n",
       "*   **LLaMA and its Derivatives (Meta AI):** Meta AI's LLaMA models, released in various sizes, have also provided empirical evidence for scaling laws. Their research highlighted that smaller models trained on more data can achieve comparable or even superior performance to larger models trained on less data, emphasizing the critical interplay between model size and dataset quality/quantity. The open-source nature of LLaMA has also spurred further research and development, with numerous fine-tuned versions demonstrating the adaptability of scaled models.\n",
       "*   **Chinchilla Scaling Laws (DeepMind):** DeepMind's Chinchilla paper provided a more refined understanding of scaling laws, suggesting that for optimal performance at a given compute budget, both model size and dataset size should be scaled proportionally. This research indicated that many previous large models were undertrained relative to their size, and that a more balanced scaling approach could yield better results.\n",
       "\n",
       "These empirical findings and case studies collectively underscore the fundamental role of scaling laws in the advancement of LLMs. They provide a theoretical and practical framework for understanding how to build more capable and versatile language models, driving innovation across the field of artificial intelligence.\n",
       "\n",
       "---\n",
       "\n",
       "### Implications and Future Directions\n",
       "\n",
       "The pervasive influence of scaling laws on the trajectory of AI research is undeniable, suggesting a continued emphasis on larger models, more extensive datasets, and increased computational resources. This trend has profound implications for the accessibility and democratization of AI development. As model sizes and training costs escalate, the barrier to entry for cutting-edge research and deployment may rise, potentially concentrating power within well-resourced organizations. This necessitates a critical examination of how to foster broader participation and prevent the exacerbation of existing digital divides.\n",
       "\n",
       "While scaling laws have demonstrably driven progress, their limitations warrant careful consideration. The assumption that performance will continue to improve predictably with scale may not hold indefinitely. Diminishing returns, the emergence of novel failure modes at extreme scales, and the inherent inefficiencies of current architectures could signal a plateau. Furthermore, the environmental impact of training massive models, in terms of energy consumption and carbon footprint, presents a significant ethical and practical challenge that demands innovative solutions, such as more efficient algorithms and hardware.\n",
       "\n",
       "Emerging trends in AI research offer promising avenues to navigate these implications and limitations. **Efficiency-focused research** is gaining momentum, exploring techniques like knowledge distillation, parameter-efficient fine-tuning (PEFT), and novel architectural designs that achieve comparable performance with significantly fewer parameters and computational resources. This includes a renewed interest in **sparse models** and **mixture-of-experts (MoE)** architectures, which allow for conditional computation, activating only relevant parts of the model for a given input.\n",
       "\n",
       "The pursuit of **multimodality** is another critical direction, moving beyond text-based models to integrate and reason across diverse data types, including images, audio, and video. This holistic approach to understanding and interacting with the world is expected to unlock new capabilities and applications. Concurrently, research into **causal reasoning** and **symbolic manipulation** aims to imbue AI systems with a deeper understanding of underlying mechanisms and relationships, moving beyond purely correlational learning.\n",
       "\n",
       "Finally, the development of **robust evaluation methodologies** and **interpretability tools** is crucial. As models become more complex and their societal impact grows, understanding *why* they make certain decisions and ensuring their reliability and fairness becomes paramount. Future research will likely focus on developing more nuanced benchmarks that assess not just raw performance but also generalization, robustness to adversarial attacks, and ethical considerations. The interplay between scaling, efficiency, multimodality, and interpretability will define the next era of AI advancement."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, List\n",
    "import operator\n",
    "\n",
    "\n",
    "# Schema for structured output to use in planning\n",
    "class Section(BaseModel):\n",
    "    name: str = Field(\n",
    "        description=\"Name for this section of the report.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n",
    "    )\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(\n",
    "        description=\"Sections of the report.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Augment the LLM with schema for structured output\n",
    "planner = llm.with_structured_output(Sections)\n",
    "\n",
    "\n",
    "from langgraph.types import Send\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    topic: str  # Report topic\n",
    "    sections: list[Section]  # List of report sections\n",
    "    completed_sections: Annotated[\n",
    "        list, operator.add\n",
    "    ]  # All workers write to this key in parallel\n",
    "    final_report: str  # Final report\n",
    "    \n",
    "\n",
    "from langgraph.types import Send\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    topic: str  # Report topic\n",
    "    sections: list[Section]  # List of report sections\n",
    "    completed_sections: Annotated[\n",
    "        list, operator.add\n",
    "    ]  # All workers write to this key in parallel\n",
    "    final_report: str  # Final report\n",
    "\n",
    "\n",
    "# Worker state\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section\n",
    "    completed_sections: Annotated[list, operator.add]\n",
    "    # The field completed_sections should be merged using operator.add, which means list concatenation.\n",
    "    # if not annotated with this operator, the field will be overwritten with the latest value returned\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def orchestrator(state: State):\n",
    "    \"\"\"Orchestrator that generates a plan for the report\"\"\"\n",
    "\n",
    "    # Generate queries\n",
    "    report_sections = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Generate a plan for the report.\"),\n",
    "            HumanMessage(content=f\"Here is the report topic: {state['topic']}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(report_sections)\n",
    "\n",
    "    return {\"sections\": report_sections.sections}\n",
    "\n",
    "\n",
    "def llm_call(state: WorkerState):\n",
    "    \"\"\"Worker writes a section of the report\"\"\"\n",
    "\n",
    "    # Generate section\n",
    "    section = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Write a report section following the provided name and description. Include no preamble for each section. Use markdown formatting.\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"Here is the section name: {state['section'].name} and description: {state['section'].description}\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Write the updated section to completed sections\n",
    "    return {\"completed_sections\": [section.content]}\n",
    "\n",
    "\n",
    "def synthesizer(state: State):\n",
    "    \"\"\"Synthesize full report from sections\"\"\"\n",
    "\n",
    "    # List of completed sections\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "\n",
    "    # Format completed section to str to use as context for final sections\n",
    "    completed_report_sections = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
    "\n",
    "    return {\"final_report\": completed_report_sections}\n",
    "\n",
    "\n",
    "# Conditional edge function to create llm_call workers that each write a section of the report\n",
    "def assign_workers(state: State):\n",
    "    \"\"\"Assign a worker to each section in the plan\"\"\"\n",
    "\n",
    "    # Kick off section writing in parallel via Send() API\n",
    "    return [Send(\"llm_call\", {\"section\": s}) for s in state[\"sections\"]]\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "orchestrator_worker_builder = StateGraph(State)\n",
    "\n",
    "# Add the nodes\n",
    "orchestrator_worker_builder.add_node(\"orchestrator\", orchestrator)\n",
    "orchestrator_worker_builder.add_node(\"llm_call\", llm_call)\n",
    "orchestrator_worker_builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "orchestrator_worker_builder.add_edge(START, \"orchestrator\")\n",
    "orchestrator_worker_builder.add_conditional_edges(\n",
    "    \"orchestrator\", assign_workers, [\"llm_call\"]\n",
    ")\n",
    "orchestrator_worker_builder.add_edge(\"llm_call\", \"synthesizer\")\n",
    "orchestrator_worker_builder.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "orchestrator_worker = orchestrator_worker_builder.compile()\n",
    "\n",
    "# Show the workflow\n",
    "display(Image(orchestrator_worker.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "state = orchestrator_worker.invoke({\"topic\": \"Create a report on LLM scaling laws\"})\n",
    "\n",
    "from IPython.display import Markdown\n",
    "Markdown(state[\"final_report\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b3bda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "# Augment the LLM with tools\n",
    "tools = [add, multiply, divide]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9d537c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Invoke\u001b[39;00m\n\u001b[1;32m     76\u001b[0m messages \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdd 3 and 4.\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m---> 77\u001b[0m messages \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     79\u001b[0m     m\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2069\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2068\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2069\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2078\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2079\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2080\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langgraph/pregel/__init__.py:1724\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1718\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1724\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1731\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langgraph/pregel/runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langgraph/utils/runnable.py:495\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    492\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    493\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langgraph/utils/runnable.py:259\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 259\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m, in \u001b[0;36mllm_call\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mllm_call\u001b[39m(state: MessagesState):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"LLM decides whether to call a tool or not\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m---> 13\u001b[0m             \u001b[43mllm_with_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant tasked with performing arithmetic on a set of inputs.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m         ]\n\u001b[1;32m     22\u001b[0m     }\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langchain_core/runnables/base.py:5352\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5348\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5349\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5350\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5351\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 690\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:951\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    927\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    939\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m    940\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    941\u001b[0m         messages,\n\u001b[1;32m    942\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    949\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m    950\u001b[0m     )\n\u001b[0;32m--> 951\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:196\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/tenacity/__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/tenacity/__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:194\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:178\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mInternalServerError\u001b[0m: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting",
      "\u001b[0mDuring task with name 'llm_call' and id '97560dd0-9656-1fa2-8452-c6739b250179'"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "from typing_extensions import Literal\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def llm_call(state: MessagesState):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(name=tool_call[\"name\"], content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "\n",
    "\n",
    "# Conditional edge function to route to the tool node or end based upon whether the LLM made a tool call\n",
    "def should_continue(state: MessagesState) -> Literal[\"environment\", END]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then perform an action\n",
    "    if last_message.tool_calls:\n",
    "        return \"Action\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"environment\", tool_node)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        # Name returned by should_continue : Name of next node to visit\n",
    "        \"Action\": \"environment\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "agent_builder.add_edge(\"environment\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "# Show the agent\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "messages = agent.invoke({\"messages\": messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2f55b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4424adb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/mambaforge/envs/llm-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling tool {'name': 'addition', 'args': {'a': 9.0, 'b': 9.0}, 'id': '052ebadb-3d01-47ed-bc4b-77da095bafd3', 'type': 'tool_call'}\n",
      "Assistant: \n",
      "User: What do you know about LangGraph?\n",
      "Assistant: I am sorry, I am unable to find any information about LangGraph with the available tools.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 128\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     \u001b[43mstream_graph_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# fallback if input() is not available\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 117\u001b[0m, in \u001b[0;36mstream_graph_updates\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstream_graph_updates\u001b[39m(user_input: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langgraph/pregel/__init__.py:1724\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1724\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1731\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langgraph/pregel/runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langgraph/utils/runnable.py:495\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/llm-env/lib/python3.13/site-packages/langgraph/utils/runnable.py:259\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 259\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n",
      "Cell \u001b[0;32mIn[1], line 54\u001b[0m, in \u001b[0;36mBasicToolNode.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# result = tool(**tool_call[\"args\"])\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m(tool_call[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     56\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(ToolMessage(content\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(result), tool_call_id\u001b[38;5;241m=\u001b[39mtool_call[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], name\u001b[38;5;241m=\u001b[39mtool_call[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'invoke'",
      "\u001b[0mDuring task with name 'tools' and id '13ab9920-0bf9-6fb6-3075-edc0e7dd2160'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 133\u001b[0m\n\u001b[1;32m    131\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat do you know about LangGraph?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m user_input)\n\u001b[0;32m--> 133\u001b[0m \u001b[43mstream_graph_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 119\u001b[0m, in \u001b[0;36mstream_graph_updates\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_input}]}):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssistant:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD_ZGym8z1GoNPFDALCFArimzKe4j0_oEU\"\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# messages = [\n",
    "#     (\n",
    "#         \"system\",\n",
    "#         \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "#     ),\n",
    "#     (\"human\", \"I love programming.\"),\n",
    "# ]\n",
    "# ai_msg = llm.invoke(messages)\n",
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import json\n",
    "\n",
    "class BasicToolNode:\n",
    "    # a node that runs the tools requested in the last AIMessage, if there are any\n",
    "    \n",
    "    def __init__(self, tools: list):\n",
    "        self.tools_by_name = {tool.__name__: tool for tool in tools} # {name : tool} dict\n",
    "    \n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            target_message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "\n",
    "        if len(messages) <= 0 or not isinstance(target_message, AIMessage):\n",
    "            raise ValueError(\"Last message must be an AIMessage, or there must be at least one message.\")\n",
    "\n",
    "        tool_calls = target_message.tool_calls\n",
    "        results = []\n",
    "        for tool_call in tool_calls:\n",
    "            tool = self.tools_by_name[tool_call[\"name\"]]\n",
    "            # result = tool(**tool_call[\"args\"])\n",
    "            result = tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "            results.append(ToolMessage(content=json.dumps(result), tool_call_id=tool_call[\"id\"], name=tool_call[\"name\"]))\n",
    "        return {\"messages\": results}\n",
    "\n",
    "\n",
    "\n",
    "class ChatbotState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "graph_builder = StateGraph(ChatbotState)\n",
    "\n",
    "\n",
    "# functions tools\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def addition(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "tools = [multiply, addition]\n",
    "tool_node = BasicToolNode(tools)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# function nodes\n",
    "def chatbot(state: ChatbotState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "def tool_router(state: ChatbotState):\n",
    "    if not state.get(\"messages\", []):\n",
    "        raise ValueError(\"No message in state\")\n",
    "\n",
    "    action_message = state[\"messages\"][-1] # only select the last one\n",
    "\n",
    "    if isinstance(action_message, AIMessage) and \\\n",
    "        hasattr(action_message, \"tool_calls\"):\n",
    "        # no tool calls, so we route to the end\n",
    "        for tool in action_message.tool_calls:\n",
    "            print(f\"calling tool {tool}\")\n",
    "        return \"tools\"\n",
    "\n",
    "    return END\n",
    "\n",
    "\n",
    "# Fix: Use a unique name for the chatbot function node\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tool_router, {\"tools\": \"tools\", END: END})\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
